<!doctype html><html lang=en><head><meta name=generator content="Hugo 0.147.8"><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Yuming Li</title><meta name=description content="I am a Master's student at Peking University, specializing in Software Engineering. My research interests lie in reinforcement learning post-training for video generative models, generative acceleration techniques, unified multimodal generative model, embodied world models with visual-language-action (VLA) integration. I am currently applying for Ph.D. programs in the fields of generative models and embodied AI."><meta name=author content="Yuming Li"><meta property="og:type" content="website"><meta property="og:url" content="https://Fredreic1849.github.io/zero-academic-page-yuming/"><meta property="og:title" content="Yuming Li"><meta property="og:description" content="I am a Master's student at Peking University, specializing in Software Engineering. My research interests lie in reinforcement learning post-training for video generative models, generative acceleration techniques, unified multimodal generative model, embodied world models with visual-language-action (VLA) integration. I am currently applying for Ph.D. programs in the fields of generative models and embodied AI."><meta property="og:image" content="/zero-academic-page-yuming/images/profile.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Yuming Li"><meta name=twitter:description content="I am a Master's student at Peking University, specializing in Software Engineering. My research interests lie in reinforcement learning post-training for video generative models, generative acceleration techniques, unified multimodal generative model, embodied world models with visual-language-action (VLA) integration. I am currently applying for Ph.D. programs in the fields of generative models and embodied AI."><meta name=twitter:image content="/zero-academic-page-yuming/images/profile.png"><link rel=canonical href=https://Fredreic1849.github.io/zero-academic-page-yuming/><link rel=icon type=image/x-icon href=/favicon.ico><link rel=stylesheet href=/zero-academic-page-yuming/css/main.min.css><link rel=stylesheet href=/zero-academic-page-yuming/css/custom.min.css><script src=/zero-academic-page-yuming/js/main.min.js defer></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css><link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,100;0,300;0,400;0,700;0,900;1,100;1,300;1,400;1,700;1,900&display=swap" rel=stylesheet></head><body class=light-mode><header class=navbar><div class=navbar-start><a href=https://Fredreic1849.github.io/zero-academic-page-yuming/>Yuming Li</a></div><div class="navbar-center hide-in-mobile"><div class=nav-links><div class=nav-item><a href=#about class=nav-link>About</a></div><div class=nav-item><a href=#education class=nav-link>Education</a></div><div class=nav-item><a href=#publications class=nav-link>Publications</a></div><div class=nav-item><a href=#experience class=nav-link>Experience</a></div><div class=nav-item><a href=yumingli/files/cv_liyuming.pdf class=nav-link>CV</a></div></div></div><div class=navbar-end><div id=i18n-selector><i class="fas fa-language"></i>
<select onchange="window.location.href=this.selectedOptions[0].value"><option value=https://Fredreic1849.github.io/zero-academic-page-yuming/ selected>English</option><option value=https://Fredreic1849.github.io/zero-academic-page-yuming/zh/>‰∏≠Êñá</option></select></div><div class=theme-toggle><button id=theme-toggle-btn aria-label="Toggle dark mode">
<i class="fas fa-moon dark-icon"></i>
<i class="fas fa-sun light-icon"></i></button></div><button type=button id=toggle-navbar-button class="toggle-navbar-button hide-in-desktop" aria-label="Toggle Navbar" aria-expanded=false aria-controls=navscreen onclick=toggleNavbar()>
<span><span class=top></span>
<span class=middle></span>
<span class=bottom></span></span></button></div></header><div id=navscreen class="navscreen hide-in-desktop"><div class=nav-screen-container><div class=nav-screen-links><div class=nav-links-item><a href=#about class=nav-link>About</a></div><div class=nav-links-item><a href=#education class=nav-link>Education</a></div><div class=nav-links-item><a href=#publications class=nav-link>Publications</a></div><div class=nav-links-item><a href=#experience class=nav-link>Experience</a></div><div class=nav-links-item><a href=yumingli/files/cv_liyuming.pdf class=nav-link>CV</a></div></div></div></div><div class=container><aside class="profile-card hide-in-mobile"><div class=profile-container><div class=profile-image><img src=/zero-academic-page-yuming/images/profile.png alt="Yuming Li" class=rounded-avatar></div><div class=profile-name><h2>Yuming Li</h2></div><div class=profile-description><p></p></div><div class=profile-quote><p></p></div><div class=social-links><a href=https://github.com/Fredreic1849 target=_blank rel="noopener noreferrer" class=social-icon><i class="fab fa-github"></i>
</a><a href="https://scholar.google.com/citations?hl=zh-CN&amp;user=LQ-kxSEAAAAJ" target=_blank rel="noopener noreferrer" class=social-icon><i class="fab fa-google-scholar"></i>
</a><a href=mailto:2301210310@stu.pku.edu.cn target=_blank rel="noopener noreferrer" class=social-icon><i class="fas fa-envelope"></i>
</a><a href=https://www.linkedin.com/in/yuming-li-192700363 target=_blank rel="noopener noreferrer" class=social-icon><i class="fab fa-linkedin"></i></a></div></div></aside><main class=main-content><article class="single-page home-page"><h1 id=about>About Me</h1><p>I am a Master&rsquo;s student at Peking University, specializing in Software Engineering. My research centers on generative models, with a focus on video generation, reinforcement learning post-training, unified multimodal generation and embodied AI. I am currently applying for Ph.D. programs in generative modeling and embodied intelligence.</p><h1 id=education>üìñ Education</h1><div class=education-entry><div class=header-left><div class=school>Peking University</div><div class=degree>Master's in Software Engineering</div></div><div class=header-right><div class=location>Beijing, China</div><div class=date>2023 ‚Äì Present</div></div></div><div class=education-entry><div class=header-left><div class=school>Northwestern Polytechnical University</div><div class=degree>Bachelor's in Computer Science and Technology</div></div><div class=header-right><div class=location>Xi'an, China</div><div class=date>2019 ‚Äì 2023</div></div></div><h1 id=publications>üìù Publications</h1><ul><li><p><em><strong>A-ToMe: Adaptive Token Merge for Diffusion Models</strong></em><br><strong>Yuming Li</strong>*, M. Lu, Z. Li, X. Chi, Q. She, S. Zhang<br><em>arXiv</em>, 2025.</p></li><li><p><em><strong>ASGDiffusion: Parallel High-Resolution Generation with Asynchronous Structure Guidance</strong></em><br><strong>Yuming Li</strong>*, P. Jia, D. Hong, Y. Jia, Q. She, R. Zhao, M. Lu, S. Zhang<br><em>arXiv</em>, 2025.</p></li><li><p><em><strong>FastInit: Fast Noise Initialization for Temporally Consistent Video Generation</strong></em><br>C. Bai, <strong>Yuming Li</strong>*, M. Lu, S. Zhang<br><em>arXiv</em>, 2025.</p></li><li><p><em><strong>ThinkLess: A Training-Free Inference-Efficient Method for Reducing Reasoning Redundancy</strong></em><br>G. Li, Y. Gao, <strong>Yuming Li</strong>, Y. Wu<br><em>arXiv</em>, 2025.</p></li><li><p><em><strong>ManipDreamer: Boosting Robotic Manipulation World Model with Action Tree and Visual Guidance</strong></em><br>Y. Li, X. Wei, X. Chi, <strong>Yuming Li</strong>, Z. Zhao, H. Wang, N. Ma, M. Lu, S. Zhang<br><em>arXiv</em>, 2025.</p></li><li><p><em><strong>PiGW: A Plug-in Generative Watermarking Framework</strong></em><br>R. Ma, M. Guo, <strong>Yuming Li</strong>, H. Zhang, C. Ma, X. Xie, S. Zhang<br><em>arXiv</em>, 2025.</p></li></ul><h1 id=experience>üíª Experience</h1><div class=experience-entry><div class=header><div class=header-left><div class=company>X-Humanoid</div><div class=role>Research Intern</div></div><div class=header-right><div class=location>Beijing, China</div><div class=date>Feb 2025 ‚Äì Dec 2025</div></div></div><div class=description><ul><li>Focused on fine-tuning Wan2.1-based video diffusion models for scene-level world simulation and post-trained reinforcement learning agents on the generated environments.</li><li>Supported downstream video-to-action tasks through integration with Multimodal Large Language Models (MLLMs) after world model construction.</li></ul></div></div><div class=experience-entry><div class=header><div class=header-left><div class=company>ByteDance</div><div class=role>Research Intern, Commercialization Department</div></div><div class=header-right><div class=location>Beijing, China</div><div class=date>Feb 2025 ‚Äì June 2025</div></div></div><div class=description><ul><li>Trained a unified <em>Multimodal Understanding & Generation</em> large model; optimized its cross‚Äëmodal tokenizer, then fine‚Äëtuned the model for image editing and introduced tabular tokens to boost classification performance.</li><li>Optimized the initial noise for video generation, enhancing the temporal consistency and quality of generated videos.</li></ul></div></div><div class=experience-entry><div class=header><div class=header-left><div class=company>Tencent</div><div class=role>Research Intern, RoboticsX</div></div><div class=header-right><div class=location>Shenzhen, China</div><div class=date>Jun 2024 ‚Äì Feb 2025</div></div></div><div class=description><ul><li>Investigated visual‚Äëlanguage‚Äëaction (VLA) models for robotic manipulation; reproduced the Pi‚Äë0 model and diffusion‚Äëpolicy.</li><li>Built a dynamic‚Äëmodel‚Äëbased dual‚Äëarm system for cloth folding, leveraging 3D point‚Äëcloud state estimation to achieve precise manipulation of flexible objects.</li></ul></div></div><div class=experience-entry><div class=header><div class=header-left><div class=company>Phigent Robotics</div><div class=role>Research Intern</div></div><div class=header-right><div class=location>Beijing, China</div><div class=date>Dec 2023 ‚Äì Jun 2024</div></div></div><div class=description><ul><li>Focused on efficient high-resolution image generation using low-memory techniques.</li></ul></div></div><div class=experience-entry><div class=header><div class=header-left><div class=company>Peking University HMI Lab</div><div class=role>Research Assistant</div></div><div class=header-right><div class=location>Beijing, China</div><div class=date>Sep 2023 ‚Äì Present</div></div></div></div></article></main></div><footer class=footer></footer></body></html>