---
title: "李聿明 (Yuming Li)"
description: >-
  我是北京大学的软件工程硕士生。我的研究兴趣在于视频生成模型的强化学习后训练、生成加速技术、统一多模态生成模型，以及融合视觉-语言-动作（VLA）的具身世界模型。我目前正在申请生成模型和具身智能领域的博士项目。
---

# 关于我 {#about}

我是北京大学的软件工程硕士生。我的研究兴趣在于视频生成模型的强化学习后训练、生成加速技术、统一多模态生成模型，以及融合视觉-语言-动作（VLA）的具身世界模型。我目前正在申请生成模型和具身智能领域的博士项目。

# 📖 教育背景 {#education}

<div class="education-entry">
    <div class="header-left">
        <div class="school">Peking University</div>
        <div class="degree">Master's in Software Engineering</div>
    </div>
    <div class="header-right">
        <div class="location">Beijing, China</div>
        <div class="date">2023 – Present</div>
    </div>
</div>

<div class="education-entry">
    <div class="header-left">
        <div class="school">Northwestern Polytechnical University</div>
        <div class="degree">Bachelor's in Computer Science and Technology</div>
    </div>
    <div class="header-right">
        <div class="location">Xi'an, China</div>
        <div class="date">2019 – 2023</div>
    </div>
</div>

# 📝 发表论文 {#publications}

- ***A-ToMe: Adaptive Token Merge for Diffusion Models*** <br>
  **Yuming Li***, M. Lu, Z. Li, X. Chi, Q. She, S. Zhang <br>
  *arXiv*, 2025.

- ***ASGDiffusion: Parallel High-Resolution Generation with Asynchronous Structure Guidance*** <br>
  **Yuming Li***, P. Jia, D. Hong, Y. Jia, Q. She, R. Zhao, M. Lu, S. Zhang <br>
  *arXiv*, 2025.

- ***FastInit: Fast Noise Initialization for Temporally Consistent Video Generation*** <br>
  C. Bai, **Yuming Li***, M. Lu, S. Zhang <br>
  *arXiv*, 2025.

- ***ThinkLess: A Training-Free Inference-Efficient Method for Reducing Reasoning Redundancy*** <br>
  G. Li, Y. Gao, **Yuming Li**, Y. Wu <br>
  *arXiv*, 2025.

- ***ManipDreamer: Boosting Robotic Manipulation World Model with Action Tree and Visual Guidance*** <br>
  Y. Li, X. Wei, X. Chi, **Yuming Li**, Z. Zhao, H. Wang, N. Ma, M. Lu, S. Zhang <br>
  *arXiv*, 2025.

- ***PiGW: A Plug-in Generative Watermarking Framework*** <br>
  R. Ma, M. Guo, **Yuming Li**, H. Zhang, C. Ma, X. Xie, S. Zhang <br>
  *arXiv*, 2025.

# 💻 个人经历 {#experience}

<div class="experience-entry">
  <div class="header">
    <div class="header-left">
      <div class="company">X-Humanoid</div>
      <div class="role">Research Intern</div>
    </div>
    <div class="header-right">
      <div class="location">Beijing, China</div>
      <div class="date">Feb 2025 – Dec 2025</div>
    </div>
  </div>
  <div class="description">
    <ul>
      <li>Focused on fine-tuning Wan2.1-based video diffusion models for scene-level world simulation and post-trained reinforcement learning agents on the generated environments.</li>
      <li>Supported downstream video-to-action tasks through integration with Multimodal Large Language Models (MLLMs) after world model construction.</li>
    </ul>
  </div>
</div>

<div class="experience-entry">
  <div class="header">
    <div class="header-left">
      <div class="company">ByteDance</div>
      <div class="role">Research Intern, Commercialization Department</div>
    </div>
    <div class="header-right">
      <div class="location">Beijing, China</div>
      <div class="date">Feb 2025 – June 2025</div>
    </div>
  </div>
  <div class="description">
    <ul>
      <li>Trained a unified <em>Multimodal Understanding &amp; Generation</em> large model; optimized its cross‑modal tokenizer, then fine‑tuned the model for image editing and introduced tabular tokens to boost classification performance.</li>
      <li>Optimized the initial noise for video generation, enhancing the temporal consistency and quality of generated videos.</li>
    </ul>
  </div>
</div>

<div class="experience-entry">
  <div class="header">
    <div class="header-left">
      <div class="company">Tencent</div>
      <div class="role">Research Intern, RoboticsX</div>
    </div>
    <div class="header-right">
      <div class="location">Shenzhen, China</div>
      <div class="date">Jun 2024 – Feb 2025</div>
    </div>
  </div>
  <div class="description">
    <ul>
      <li>Investigated visual‑language‑action (VLA) models for robotic manipulation; reproduced the Pi‑0 model and diffusion‑policy.</li>
      <li>Built a dynamic‑model‑based dual‑arm system for cloth folding, leveraging 3D point‑cloud state estimation to achieve precise manipulation of flexible objects.</li>
    </ul>
  </div>
</div>

<div class="experience-entry">
  <div class="header">
    <div class="header-left">
      <div class="company">Phigent Robotics</div>
      <div class="role">Research Intern</div>
    </div>
    <div class="header-right">
      <div class="location">Beijing, China</div>
      <div class="date">Dec 2023 – Jun 2024</div>
    </div>
  </div>
  <div class="description">
    <ul>
      <li>Focused on efficient high-resolution image generation using low-memory techniques.</li>
    </ul>
  </div>
</div>

<div class="experience-entry">
  <div class="header">
    <div class="header-left">
      <div class="company">Peking University HMI Lab</div>
      <div class="role">Research Assistant</div>
    </div>
    <div class="header-right">
      <div class="location">Beijing, China</div>
      <div class="date">Sep 2023 – Present</div>
    </div>
  </div>
</div>